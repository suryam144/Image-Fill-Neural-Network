{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Functions\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from scipy.stats import bernoulli, norm\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variable_split(mat): # Gets Y values after correlation (Selecting a Variable to Split On)\n",
    "    temp_mat = pd.DataFrame(mat)\n",
    "    corr_col = mat.corr().iloc[:,-1]\n",
    "    corr_col = corr_col[:-1].abs().sort_values(ascending = False)\n",
    "    return pd.DataFrame(corr_col).index[0]\n",
    "\n",
    "def midpt_arr(mat, ind): #Gets Midpoints based on the index found in variable_split [Treat as alpha values to find the best one]\n",
    "    mid_mat = []\n",
    "    mat_sort = pd.DataFrame(mat[ind].sort_values(ascending = False))\n",
    "    for i in range(len(mat_sort) - 1):\n",
    "        midpt = (mat_sort.iloc[i] + mat_sort.iloc[i+1]) / 2\n",
    "        mid_mat.append(midpt)\n",
    "    return pd.DataFrame(mid_mat)\n",
    "\n",
    "def threshold_calc(mat): #Calculates the Thresholds after having the variable to split on and the midpoints\n",
    "    feature = variable_split(mat)\n",
    "    midpt_mat = midpt_arr(mat, feature)\n",
    "    sorted_mat = mat[feature].sort_values(ascending = False).reset_index()\n",
    "    err_test = []\n",
    "\n",
    "    for i in range(len(mat) - 1):\n",
    "        alpha = float(midpt_mat.values[i])\n",
    "\n",
    "        left_partition = pd.DataFrame(sorted_mat[(sorted_mat[feature] <= alpha)])\n",
    "        right_partition = pd.DataFrame(sorted_mat[(sorted_mat[feature] > alpha)])        \n",
    "        left_error = 0\n",
    "        right_error = 0\n",
    "\n",
    "        if(len(left_partition) > 0):\n",
    "            y_left_avg = float(left_partition.iloc[:,-1:].mean())\n",
    "            for j in range(len(left_partition)):\n",
    "                error = (1 / len(left_partition)) * (float(left_partition.iloc[:,-1:].values[j]) - y_left_avg)**2\n",
    "                left_error += error\n",
    "        if(len(right_partition) > 0):\n",
    "             y_right_avg = float(right_partition.iloc[:,-1:].mean())\n",
    "             for j in range(len(right_partition)):\n",
    "                error = (1 / len(right_partition)) * (float(right_partition.iloc[:,-1:].values[j]) - y_right_avg)**2\n",
    "                right_error += error\n",
    "        lr_data = len(left_partition) + len(right_partition)\n",
    "        total_error = ((len(left_partition) / lr_data) * left_error) + ((len(right_partition) / lr_data) * right_error)\n",
    "        err_test.append(total_error)\n",
    "\n",
    "    min_err = pd.DataFrame(err_test).sort_values(0, ascending = True)\n",
    "    min_err_res = min_err.index[0]\n",
    "    return sorted_mat['index'][min_err_res]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a class called Node to use as the tree depth\n",
    "class Node:\n",
    "    def __init__(self, name = \"Leaf\", feature_index=None, threshold=None, left=None, right=None, dataset=None, depth=None):\n",
    "        self.name = name\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.dataset = dataset\n",
    "        self.depth = depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generates a tree with a node inserted as the starting point. Uses all the functions above to generate a tree based on the thresholds of the data. \n",
    "def tree_sample_size(node, depth):\n",
    "    node.depth = depth\n",
    "    if((len(node.dataset) <= 1)):\n",
    "        return node\n",
    "    feature = variable_split(node.dataset)\n",
    "    threshold = threshold_calc(node.dataset)\n",
    "    temp_dataset = pd.DataFrame(node.dataset)\n",
    "    if((len(node.dataset) < temp_dataset[feature][threshold])):\n",
    "        return node\n",
    "        \n",
    "    node.name = feature\n",
    "    node.feature_index = feature\n",
    "    node.threshold = threshold\n",
    "\n",
    "    left_partition = pd.DataFrame(temp_dataset[temp_dataset[feature] <= temp_dataset[feature][threshold]]).reset_index(drop = True)\n",
    "    right_partition = pd.DataFrame(temp_dataset[temp_dataset[feature] > temp_dataset[feature][threshold]]).reset_index(drop = True)\n",
    "    \n",
    "    if(len(right_partition) == 0):\n",
    "        left_partition = pd.DataFrame(temp_dataset[temp_dataset[feature] < temp_dataset[feature][threshold]]).reset_index(drop = True)\n",
    "        right_partition = pd.DataFrame(temp_dataset[temp_dataset[feature] >= temp_dataset[feature][threshold]]).reset_index(drop = True)\n",
    "    \n",
    "    node.left = Node(dataset = left_partition)\n",
    "    node.right = Node(dataset = right_partition)\n",
    "\n",
    "    node.left = tree_sample_size(node.left, depth + 1)\n",
    "    node.right = tree_sample_size(node.right, depth + 1)\n",
    "\n",
    "    return node\n",
    "\n",
    "#Calculates the error upon the decision tree being made. Returns the Y values of all the values after the decision tree has been traversed\n",
    "def error_calc(node, dataset):\n",
    "    mat = dataset\n",
    "    total_sum = []\n",
    "    sum = 0\n",
    "    for i in range(len(mat)):\n",
    "        queue = []\n",
    "        temp = node\n",
    "        refresh = 0\n",
    "        queue.append(temp)\n",
    "        while ((len(queue) > 0) and refresh == 0):\n",
    "            temp = queue.pop(0)\n",
    "            if temp.name == \"Leaf\":\n",
    "                curr_mat = pd.DataFrame(temp.dataset)\n",
    "                sum = curr_mat.iloc[:,-1].mean()\n",
    "                refresh = 1\n",
    "            else: \n",
    "                if(mat[temp.feature_index][i] <= node.dataset[temp.feature_index][temp.threshold]):\n",
    "                    if temp.left != None:\n",
    "                        queue.append(temp.left) \n",
    "                else:\n",
    "                    if temp.right != None:\n",
    "                        queue.append(temp.right)\n",
    "        total_sum.append(sum)\n",
    "    return total_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generates Dataset for both leaves and wood image\n",
    "leaves_image = 'Leaves_Masked.jpg'\n",
    "woods_image = 'Wood_Masked.jpg'\n",
    "\n",
    "image_leaf = Image.open(leaves_image)\n",
    "image_wood = Image.open(woods_image)\n",
    "arr_image_leaf = np.asarray(image_leaf)\n",
    "arr_image_woods = np.asarray(image_wood)\n",
    "\n",
    "white_count = 0\n",
    "leaves_df = []\n",
    "Y_r = []\n",
    "Y_g = []\n",
    "Y_b = []\n",
    "for i in range(0,900):\n",
    "    for j in range(0,900):\n",
    "        if((int(arr_image_leaf[i][j][0]) > 235) & (int(arr_image_leaf[i][j][1]) > 235) & (int(arr_image_leaf[i][j][2]) > 235)): white_count+= 1\n",
    "        else:\n",
    "            leaves_df.append([int(arr_image_leaf[i][j][0]), int(arr_image_leaf[i][j][1]), int(arr_image_leaf[i][j][2])])\n",
    "            if(j!= 899):\n",
    "                Y_r.append(int(arr_image_leaf[i][j+1][0]))\n",
    "                Y_g.append(int(arr_image_leaf[i][j+1][1]))\n",
    "                Y_b.append(int(arr_image_leaf[i][j+1][2]))\n",
    "            else:\n",
    "                Y_r.append(0)\n",
    "                Y_g.append(0)\n",
    "                Y_b.append(0)\n",
    "\n",
    "white_count = 0\n",
    "woods_df = []\n",
    "Y_r_w = []\n",
    "Y_g_w = []\n",
    "Y_b_w = []\n",
    "for i in range(0,900):\n",
    "    for j in range(0,900):\n",
    "        if((int(arr_image_woods[i][j][0]) > 235) & (int(arr_image_woods[i][j][1]) > 235) & (int(arr_image_woods[i][j][2]) > 235)): white_count+= 1\n",
    "        else:\n",
    "            woods_df.append([int(arr_image_woods[i][j][0]), int(arr_image_woods[i][j][1]), int(arr_image_woods[i][j][2])])\n",
    "            if(j!= 899):\n",
    "                Y_r_w.append(int(arr_image_woods[i][j+1][0]))\n",
    "                Y_g_w.append(int(arr_image_woods[i][j+1][1]))\n",
    "                Y_b_w.append(int(arr_image_woods[i][j+1][2]))\n",
    "            else:\n",
    "                Y_r_w.append(0)\n",
    "                Y_g_w.append(0)\n",
    "                Y_b_w.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates 3 separate datasets for wood and leaves image, one for red values, one for green values, and one for blue values\n",
    "leaves_df = pd.DataFrame(leaves_df)\n",
    "Y_r_df = pd.DataFrame(Y_r)\n",
    "Y_g_df = pd.DataFrame(Y_g)\n",
    "Y_b_df = pd.DataFrame(Y_b)\n",
    "synth_data_red = pd.merge(leaves_df, Y_r_df, left_index=True, right_index=True)\n",
    "synth_data_red = synth_data_red.rename(columns = {'0_x': 0, '0_y': 3})\n",
    "synth_data_green = pd.merge(leaves_df, Y_g_df, left_index=True, right_index=True)\n",
    "synth_data_green = synth_data_green.rename(columns = {'0_x': 0, '0_y': 3})\n",
    "synth_data_blue = pd.merge(leaves_df, Y_b_df, left_index=True, right_index=True)\n",
    "synth_data_blue = synth_data_blue.rename(columns = {'0_x': 0, '0_y': 3})\n",
    "\n",
    "\n",
    "woods_df = pd.DataFrame(woods_df)\n",
    "Y_r_w_df = pd.DataFrame(Y_r_w)\n",
    "Y_g_w_df = pd.DataFrame(Y_g_w)\n",
    "Y_b_w_df = pd.DataFrame(Y_b_w)\n",
    "synth_data_red_w = pd.merge(woods_df, Y_r_w_df, left_index=True, right_index=True)\n",
    "synth_data_red_w = synth_data_red_w.rename(columns = {'0_x': 0, '0_y': 3})\n",
    "synth_data_green_w = pd.merge(woods_df, Y_g_w_df, left_index=True, right_index=True)\n",
    "synth_data_green_w = synth_data_green_w.rename(columns = {'0_x': 0, '0_y': 3})\n",
    "synth_data_blue_w = pd.merge(woods_df, Y_b_w_df, left_index=True, right_index=True)\n",
    "synth_data_blue_w = synth_data_blue_w.rename(columns = {'0_x': 0, '0_y': 3})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a decision tree for training data\n",
    "mat_train = pd.DataFrame(synth_data_red).loc[0:2000]\n",
    "mat_test = pd.DataFrame(synth_data_red).loc[0:500]\n",
    "tree_node_red = Node(dataset = mat_train)\n",
    "test_tree_red = tree_sample_size(tree_node_red, 1)\n",
    "\n",
    "mat_train = pd.DataFrame(synth_data_green).loc[0:2000]\n",
    "mat_test = pd.DataFrame(synth_data_green).loc[0:500]\n",
    "tree_node_green = Node(dataset = mat_train)\n",
    "test_tree_green = tree_sample_size(tree_node_green, 1)\n",
    "\n",
    "mat_train = pd.DataFrame(synth_data_blue).loc[0:2000]\n",
    "mat_test = pd.DataFrame(synth_data_blue).loc[0:500]\n",
    "tree_node_blue = Node(dataset = mat_train)\n",
    "test_tree_blue = tree_sample_size(tree_node_blue, 1)\n",
    "\n",
    "mat_train = pd.DataFrame(synth_data_red_w).loc[0:2000]\n",
    "mat_test = pd.DataFrame(synth_data_red_w).loc[0:500]\n",
    "tree_node_red_w = Node(dataset = mat_train)\n",
    "test_tree_red_w = tree_sample_size(tree_node_red_w, 1)\n",
    "\n",
    "mat_train = pd.DataFrame(synth_data_green_w).loc[0:2000]\n",
    "mat_test = pd.DataFrame(synth_data_green_w).loc[0:500]\n",
    "tree_node_green_w = Node(dataset = mat_train)\n",
    "test_tree_green_w = tree_sample_size(tree_node_green_w, 1)\n",
    "\n",
    "mat_train = pd.DataFrame(synth_data_blue_w).loc[0:2000]\n",
    "mat_test = pd.DataFrame(synth_data_blue_w).loc[0:500]\n",
    "tree_node_blue_w = Node(dataset = mat_train)\n",
    "test_tree_blue_w = tree_sample_size(tree_node_blue_w, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uses Decision trees to predict results within white space. Additionally appends predictions to original array\n",
    "leaves_image = 'Leaves_Masked.jpg'\n",
    "wood_image = 'Wood_Masked.jpg'\n",
    "\n",
    "temp_tree_red = test_tree_red\n",
    "temp_tree_green = test_tree_green\n",
    "temp_tree_blue = test_tree_blue\n",
    "image = Image.open(leaves_image)\n",
    "arr_image = np.asarray(image)\n",
    "\n",
    "temp_tree_red_w = test_tree_red_w\n",
    "temp_tree_green_w = test_tree_green_w\n",
    "temp_tree_blue_w = test_tree_blue_w\n",
    "image = Image.open(leaves_image)\n",
    "arr_image = np.asarray(image)\n",
    "image_wood = Image.open(wood_image)\n",
    "arr_image_woods = np.asarray(image_wood)\n",
    "\n",
    "vals_two = []\n",
    "for i in range(300, 600):\n",
    "    for j in range(300, 600):\n",
    "        red_df = pd.DataFrame(synth_data_red[i*900 + j: i*900 + j + 1]).reset_index(drop = True)\n",
    "        green_df = pd.DataFrame(synth_data_blue[i*900 + j: i*900 + j + 1]).reset_index(drop = True)\n",
    "        blue_df = pd.DataFrame(synth_data_blue[i*900 + j: i*900 + j + 1]).reset_index(drop = True)\n",
    "        r_val = error_calc(test_tree_red, red_df)\n",
    "        g_val = error_calc(test_tree_green, green_df)\n",
    "        b_val = error_calc(test_tree_blue, blue_df)\n",
    "        vals_two.append([r_val[0], g_val[0], b_val[0]])\n",
    "\n",
    "k = 0\n",
    "for i in range(300, 600):\n",
    "    for j in range(300,600):\n",
    "        arr_image_leaf[i][j] = vals_two[k]\n",
    "        k+= 1\n",
    "\n",
    "vals_two_w = []\n",
    "for i in range(300, 600):\n",
    "    for j in range(300, 600):\n",
    "        red_df = pd.DataFrame(synth_data_red_w[i*900 + j: i*900 + j + 1]).reset_index(drop = True)\n",
    "        green_df = pd.DataFrame(synth_data_blue_w[i*900 + j: i*900 + j + 1]).reset_index(drop = True)\n",
    "        blue_df = pd.DataFrame(synth_data_blue_w[i*900 + j: i*900 + j + 1]).reset_index(drop = True)\n",
    "        r_val = error_calc(test_tree_red_w, red_df)\n",
    "        g_val = error_calc(test_tree_green_w, green_df)\n",
    "        b_val = error_calc(test_tree_blue_w, blue_df)\n",
    "        vals_two_w.append([r_val[0], g_val[0], b_val[0]])\n",
    "\n",
    "k = 0\n",
    "for i in range(300, 600):\n",
    "    for j in range(300,600):\n",
    "        arr_image_woods[i][j] = vals_two_w[k]\n",
    "        k+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns image with appended prediction over white space\n",
    "leaf_final = Image.fromarray(arr_image_leaf)\n",
    "wood_final = Image.fromarray(arr_image_woods)\n",
    "leaf_final.save('final_leaf_dt_png')\n",
    "wood_final.save('final_wood_dt.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1960ac14023d5e43c9c0c90c2107231139d9766740fd51f3b9b39f7b96ea5acc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
